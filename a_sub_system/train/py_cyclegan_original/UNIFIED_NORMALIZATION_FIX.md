# CycleGAN Bâ†’Aâ†’B Cycle Loss å¼‚å¸¸ä¿®å¤æŠ¥å‘Š

## é—®é¢˜æ‘˜è¦

è®­ç»ƒæ—¥å¿—æ˜¾ç¤º `loss/G_cycle_B` (Bâ†’Aâ†’B å¾ªç¯æŸå¤±) é«˜è¾¾ **1437.7**ï¼Œè¿œè¶…æ­£å¸¸èŒƒå›´ï¼ˆ0.1ï½1.0ï¼‰ï¼Œè€Œ `loss/G_cycle_A` ä»…ä¸º 0.26ã€‚

## æ ¹æœ¬åŸå› åˆ†æ

### é—®é¢˜å®šä½

åœ¨åŸå§‹ `data/leaf_dataset.py:59-74` ä¸­ï¼š

```python
def _compute_normalization_params(self):
    all_features_a = np.vstack(self.domain_a_features)
    all_features_b = np.vstack(self.domain_b_features)

    self.mean_a = np.mean(all_features_a, axis=0)
    self.std_a = np.std(all_features_a, axis=0) + 1e-8

    self.mean_b = np.mean(all_features_b, axis=0)  # âŒ é—®é¢˜æ‰€åœ¨
    self.std_b = np.std(all_features_b, axis=0) + 1e-8
```

**Domain A å’Œ Domain B ä½¿ç”¨äº†ä¸åŒçš„å½’ä¸€åŒ–å‚æ•°**ï¼Œå¯¼è‡´ä¸¤ä¸ªåŸŸåœ¨å½’ä¸€åŒ–åå¤„äºä¸åŒçš„æ•°å€¼å°ºåº¦ã€‚

### ä¸ºä»€ä¹ˆåªæœ‰ G_cycle_B å¼‚å¸¸ï¼Ÿ

1. **æ•°å€¼å°ºåº¦ä¸åŒ¹é…**
   - å¦‚æœ Domain B çš„ `std_b` å¾ˆå°ï¼Œå½’ä¸€åŒ–ä¼šæ”¾å¤§æ•°æ®
   - Cycle Loss ä½¿ç”¨ L1 è·ç¦»ï¼Œåœ¨æ”¾å¤§çš„ç©ºé—´ä¸­è®¡ç®—å¯¼è‡´ loss çˆ†ç‚¸

2. **è®­ç»ƒæ•°æ®ç»Ÿè®¡**
   - Domain A (CPC): 3098 samples
   - Domain B (MAFAULDA): 1951 samples
   - ä¸¤ä¸ªåŸŸçš„åŸå§‹æ•°æ®åˆ†å¸ƒå¯èƒ½å·®å¼‚å¾ˆå¤§

## è§£å†³æ–¹æ¡ˆï¼šç»Ÿä¸€å½’ä¸€åŒ–

### ä¿®æ”¹å†…å®¹

#### 1. `data/leaf_dataset.py` - ä¸»è¦ä¿®æ”¹

```python
def _compute_normalization_params(self):
    """è®¡ç®—ç‰¹å¾çš„å‡å€¼å’Œæ ‡å‡†å·® - ä½¿ç”¨ç»Ÿä¸€å½’ä¸€åŒ–"""
    all_features_a = np.vstack(self.domain_a_features)
    all_features_b = np.vstack(self.domain_b_features)

    # âœ… ç»Ÿä¸€å½’ä¸€åŒ–ï¼šåˆå¹¶ä¸¤ä¸ªåŸŸè®¡ç®—å…¨å±€ç»Ÿè®¡
    all_features_combined = np.vstack([all_features_a, all_features_b])

    global_mean = np.mean(all_features_combined, axis=0)
    global_std = np.std(all_features_combined, axis=0) + 1e-8

    # ä¸¤ä¸ªåŸŸä½¿ç”¨ç›¸åŒçš„å½’ä¸€åŒ–å‚æ•°
    self.mean_a = global_mean
    self.std_a = global_std
    self.mean_b = global_mean
    self.std_b = global_std

    logger.info(
        f"Normalization params computed (unified) - "
        f"Global: mean={global_mean.mean():.4f}, std={global_std.mean():.4f}"
    )
    # æ·»åŠ åŸå§‹æ•°æ®ç»Ÿè®¡æ—¥å¿—...
```

#### 2. `scripts/convert.py` - æ·»åŠ æ³¨é‡Š

åœ¨ç¬¬64è¡Œæ·»åŠ æ³¨é‡Šè¯´æ˜ç»Ÿä¸€å½’ä¸€åŒ–ï¼š
```python
# æ³¨æ„ï¼šä½¿ç”¨çµ±ä¸€æ­¸ä¸€åŒ–æ™‚ï¼Œmean_a = mean_b, std_a = std_b
# ä½†ç‚ºäº†å‘å¾Œå…¼å®¹æ€§ï¼Œæˆ‘å€‘ä»ç„¶æ ¹æ“šæ–¹å‘é¸æ“‡åƒæ•¸
```

#### 3. `scripts/batch_domain_conversion.py` - æ·»åŠ æ³¨é‡Š

åœ¨ç¬¬75è¡Œæ·»åŠ æ³¨é‡Šè¯´æ˜ç»Ÿä¸€å½’ä¸€åŒ–ï¼š
```python
# æ³¨æ„ï¼šä½¿ç”¨çµ±ä¸€æ­¸ä¸€åŒ–æ™‚ï¼Œmean_a = mean_b, std_a = std_b
# ä½†ç‚ºäº†å‘å¾Œå…¼å®¹æ€§ï¼Œæˆ‘å€‘ä»ç„¶ä¿ç•™æ‰€æœ‰åƒæ•¸
```

### æµ‹è¯•éªŒè¯

è¿è¡Œ `test_unified_normalization.py` ç¡®è®¤ï¼š

âœ… **ç»Ÿä¸€å½’ä¸€åŒ–å·²ç”Ÿæ•ˆ**
- `mean_a = mean_b`
- `std_a = std_b`
- ä¸¤ä¸ªåŸŸåœ¨ç›¸åŒçš„æ•°å€¼ç©ºé—´ä¸­

âœ… **å‘åå…¼å®¹æ€§**
- æ¨ç†è„šæœ¬ä»ç„¶æ­£å¸¸å·¥ä½œ
- å½’ä¸€åŒ–å‚æ•°æ ¼å¼ä¿æŒä¸å˜

## é¢„æœŸæ•ˆæœ

### ä¿®å¤å‰
- `loss/G_cycle_A`: 0.26 (æ­£å¸¸)
- `loss/G_cycle_B`: 1437.7 (âŒ å¼‚å¸¸)

### ä¿®å¤åï¼ˆé¢„æœŸï¼‰
- `loss/G_cycle_A`: 0.2ï½0.3 (æ­£å¸¸)
- `loss/G_cycle_B`: 0.2ï½0.3 (âœ… æ­£å¸¸)

ä¸¤ä¸ªæ–¹å‘çš„ Cycle Loss åº”è¯¥åœ¨ç›¸è¿‘çš„æ•°å€¼èŒƒå›´å†…ã€‚

## ä¸‹ä¸€æ­¥æ“ä½œ

### 1. æ¸…ç†æ—§æ¨¡å‹

```bash
cd a_sub_system/train/py_cyclegan
rm -rf checkpoints/*
rm -rf logs/cyclegan/*
```

### 2. é‡æ–°è®­ç»ƒ

```bash
python scripts/train.py
```

### 3. ç›‘æ§è®­ç»ƒæŒ‡æ ‡

åœ¨ TensorBoard ä¸­é‡ç‚¹å…³æ³¨ï¼š

- âœ… `loss/D_A_epoch`: åº”è¯¥åœ¨ 0.1ï½0.5
- âœ… `loss/D_B_epoch`: åº”è¯¥åœ¨ 0.1ï½0.5
- âœ… `loss/G_cycle_A`: åº”è¯¥åœ¨ 0.1ï½1.0
- âœ… `loss/G_cycle_B`: **åº”è¯¥åœ¨ 0.1ï½1.0ï¼ˆä¸å†æ˜¯ 1400+ï¼‰**
- âœ… `loss/G_GAN_AB`: åº”è¯¥åœ¨ 0.5ï½1.0
- âœ… `loss/G_GAN_BA`: åº”è¯¥åœ¨ 0.5ï½1.0

### 4. éªŒè¯å½’ä¸€åŒ–å‚æ•°

è®­ç»ƒå®Œæˆåæ£€æŸ¥ï¼š

```bash
cat checkpoints/normalization_params.json
```

åº”è¯¥çœ‹åˆ° `mean_a` å’Œ `mean_b` æ•°å€¼ç›¸åŒï¼Œ`std_a` å’Œ `std_b` æ•°å€¼ç›¸åŒã€‚

## æŠ€æœ¯ç»†èŠ‚

### ä¸ºä»€ä¹ˆç»Ÿä¸€å½’ä¸€åŒ–æœ‰æ•ˆï¼Ÿ

1. **ç›¸åŒçš„æ•°å€¼ç©ºé—´**
   - ä¸¤ä¸ªåŸŸå½’ä¸€åŒ–åå¤„äºç›¸åŒçš„åˆ†å¸ƒç©ºé—´
   - Cycle Loss è®¡ç®—æ›´åˆç†

2. **é¿å…æ•°å€¼çˆ†ç‚¸**
   - ä¸ä¼šå› ä¸ºæŸä¸ªåŸŸçš„ std è¿‡å°è€Œå¯¼è‡´æ•°å€¼æ”¾å¤§
   - Loss å€¼åœ¨åˆç†èŒƒå›´å†…

3. **æ›´å®¹æ˜“æ”¶æ•›**
   - ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨åœ¨ç›¸åŒçš„æ•°å€¼ç©ºé—´ä¸­è®­ç»ƒ
   - è®­ç»ƒæ›´ç¨³å®š

### ç†è®ºæ”¯æŒ

åœ¨ CycleGAN åŸè®ºæ–‡ä¸­ï¼Œä½¿ç”¨ç»Ÿä¸€çš„å½’ä¸€åŒ–æ˜¯å¸¸è§åšæ³•ï¼š
- ç¡®ä¿ä¸¤ä¸ªåŸŸåœ¨ç›¸åŒçš„æ•°å€¼ç©ºé—´
- ç®€åŒ–æ¨¡å‹è®­ç»ƒ
- æé«˜è®­ç»ƒç¨³å®šæ€§

## ç›¸å…³æ–‡ä»¶

- âœ… ä¿®æ”¹ï¼š`data/leaf_dataset.py`
- âœ… æ›´æ–°ï¼š`scripts/convert.py`
- âœ… æ›´æ–°ï¼š`scripts/batch_domain_conversion.py`
- âœ… æ–°å¢ï¼š`test_unified_normalization.py`
- ğŸ“„ æœ¬æ–‡æ¡£ï¼š`UNIFIED_NORMALIZATION_FIX.md`

## è”ç³»ä¸æ”¯æŒ

å¦‚æœé‡æ–°è®­ç»ƒå `loss/G_cycle_B` ä»ç„¶å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ï¼š

1. æ•°æ®è´¨é‡ï¼šç¡®è®¤ MAFAULDA æ•°æ®æ²¡æœ‰å¼‚å¸¸å€¼
2. æ•°æ®é‡ï¼šä¸¤ä¸ªåŸŸçš„æ ·æœ¬æ•°æ˜¯å¦ä¸¥é‡ä¸å¹³è¡¡
3. ç‰¹å¾æå–ï¼šç¡®è®¤ LEAF ç‰¹å¾æå–æ­£ç¡®

å¯ä»¥è¿è¡Œ `debug_training_data.py` è¿›è¡Œè¯¦ç»†çš„æ•°æ®è¯Šæ–­ã€‚

---

**ä¿®å¤æ—¥æœŸ**: 2025-11-05
**æµ‹è¯•çŠ¶æ€**: âœ… é€šè¿‡
**å»ºè®®**: ç«‹å³é‡æ–°è®­ç»ƒæ¨¡å‹